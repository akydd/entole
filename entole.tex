\documentclass{article}
\usepackage{textgreek}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{tabularx}

\newcommand{\entole}{\textepsilon\textnu\texttau\textomikron\textlambda\textepsilon\xspace}

\title{Applying machine learning to New Testament Greek}
\author{Alan Kydd}

\begin{document}

\maketitle

\begin{abstract}
The Koine Greek word \entole is often translated to the English
word ``commandment'' in the King James bible.  The word ``commandment'' itself
has various meanings depending on the context, as there are various tyoes of
``commandments'' in the Bible.  Sometimes the type
is obvious, such as when the ``commandment'' being referred to is explicity
stated.  Other times, the type must be inferred from other contextual
data.

We use use TensorFlow to train a deep neural
network to categorize the various translations of \entole,
and it's various forms, when the type of ``commandment'' is explicit. 
Then, for those instances when the type is not explicitly stated,  we use the network 
to determine the type.
\end{abstract}

\section{Introduction}
The word \entole, and it's variants, appear 67 times in the Greek New 
Testament, spanning 16 separate books.  \entole is often, but not always, translated as
``commandment'' in the King James Bible.  The type of commandment being referred to varies from text to 
text.

At times the meaning of ``commandment'' is clear from the context in which
the word appears.  For example, Todo.  However, there are times when the precise
meaning is not clear.  For example, Todo.  

\section{Methods}
36 of the total 67 occurences of \entole and its variants can each be explicitly linked to a specific
commandment or group of commandments.
We classify each of these 36 occurences according to the type of commandment, or commandments,
to which each occurence belongs: ``Torah'', ``Decalogue'' (itself a part
of the Torah), and ``Other''.  The ``Other'' type includes man-made laws
and instructions from one person to another, among others.

\begin{table}
    \begin{tabularx}{\textwidth}{llX}
    \toprule
    \textbf{Verse} & \textbf{Type} & \textbf{Reason} \\
    \midrule
    Matthew 5:19 & Torah & Jesus uses the commandment as belonging to the Law \\
    Matthew 15:3 & Torah & Refers to Ex. 20:12, Ex. 21:17, Lev. 20:9 \\
    Matthew 19:17 & Torah & Five Decalogue commandments mentioned, plus Lev. 19:18 \\
    Matthew 22:38 & Torah & Lev. 19:18, Deut. 6:5\\
    Matthew 22:40 & Torah & Lev. 19:18, Deut. 6:5\\
    Mark 7:7 & Other & phrase is ``commandments of men'' \\
    Mark 7:8 & Torah & Verse 10 refers to Ex. 20:12, Ex. 21:17, Lev. 20:9\\
    Mark 7:9 & Torah & Verse 10 refers to Ex. 20:12, Ex. 21:17, Lev. 20:9\\
    Mark 10:5 & Torah & Refers to divorce law, Deut. 24:1 for example\\
    Mark 12:31 & Torah & \\
    Luke 15:29 & Other & \\
    Luke 18:20 & Decalogue & \\
    Luke 23:56 & Decalogue & \\
    John 10:18 & Other & \\
    John 11:57 & Other & \\
    John 12:49 & Other & \\
    John 13:50 & Other & \\
    John 13:34 & Other & \\
    John 15:12 & Other & \\
    Acts 17:15 & Other & \\
    Romans 7:8 & Decalogue & \\
    Romans 13:9 & Decalogue & \\
    1 Cor. 14:37 & Other & \\
    Eph. 6:2 & Decalogue & \\
    Col. 4:10 & Other & \\
    1 Tim. 6:14 & Other & \\
    Titus 1:14 & Other & \\
    Heb. 7:5 & Torah & \\
    Heb. 7:16 & Torah & \\
    Heb. 7:18 & Torah & \\
    Heb. 9:19 & Torah & \\
    1 John 3:23 & Other & \\
    1 John 3:23 & Other & \\
    1 John 3:24 & Torah & \\
    1 John 4:21 & Other & \\
    2 John 1:5 & Other & \\
    \bottomrule
\end{tabularx}
    \caption{Classification of \entole}
    \label{training}
\end{table}

We use the set of classified data to train a neural network to classify the remaining 34
occurences of \entole and its variants.  Thus
we use a multilayer perceptron, implemented by TensorFlow's \texttt{tf.estimator.DNNClassifier}.

The ouput layer consists of three neurons, one for each type.

We use the following properties of each occurence for the features, or inputs, for the input layer:
Location of the occurence: if two occurences of \entole appear in the same verse, chapter, or book,
then perhaps the two occurences belong to the same type.  Traditional author of the text: who was
the author, and what was his/her cultural or religious background?  Given author of the text: similar
to the traditional author.  Details about dialogue, if any: was the word used in conversation?  If so,
who were the parties involved, and what was their cultural or religious background?  Intended audience:
who was the intended audience of the book in which the occurence appears?

We use a single hidden layer.  There are multiple methods of determining how many neurons
to include in this layer.  In this paper we use two rules of thumb provided in~\cite{Heaton2008}.

\begin{eqnarray}
    N_h & = & \frac{2 * N_i}{3} + N_o\\
    N_h & = & \frac{N_i + N_o}{2}
\end{eqnarray}
where $N_h$ is the number of neurons in the hidden layer, $N_i$ is the number of neurons in the input
layer, and $N_o$ is the number of neurons in the output layer.

The criteria selected for We track the location, details about the author, traditional or otherwise.
If \entole was used within dialogue, we track the details of the dialogue:
the parties involved, and their respective backgrounds.

\section{Results}
Here we can see that\ldots

\section{Discussion}
Test

\begin{thebibliography}{1}

\bibitem{Heaton2008}
    Jeff Heaton,
    \emph{Introduction to Neural Networks for Java},
    Heaton Research Incorporated,
    Second Edition,
    2008

\end{thebibliography}

\end{document}
